{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Student Grade Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../input/iitg-students-grade2/grade_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final processing of String variables \n",
    "def top_or_not(value, top_values):\n",
    "    if value in top_values:\n",
    "        return value\n",
    "    else:\n",
    "        return jellyfish.soundex(\"other\")\n",
    "\n",
    "def string_col_preprocess(data, col, n):\n",
    "    # Normal string preprocessing\n",
    "    data[col] = data[col].str.lower().str.strip().fillna(\"none\").replace({'-':\"none\", '--':'none', '---':'none'})\n",
    "    \n",
    "    # Creating a new column with soundex encoding\n",
    "    data[col+\"Sound\"] = data[col].apply(lambda x: jellyfish.soundex(x))\n",
    "    \n",
    "    # Now taking only first n common values and making others as \"others\"\n",
    "    top_values = list(data[col+'Sound'].value_counts().sort_values(ascending=False).keys()[:n])\n",
    "    data[col+'Sound'] = data[col+'Sound'].apply(lambda x: top_or_not(x, top_values))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bekaar_features = ['Which Technical Clubs are you part of ?', 'Which Cultural Clubs are you part of?',\n",
    "                  'Addiction?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "le = LabelEncoder()\n",
    "def preprocess_data(data):\n",
    "    \n",
    "    data.drop(['Timestamp', 'Survey taken by(CnA Member)'], axis=1, inplace=True)\n",
    "    data = data.drop(bekaar_features, axis=1)\n",
    "    \n",
    "    # Removing entries with less than 5 CPI\n",
    "    data = data.drop(data[data['CPI ']<5].index)\n",
    "    data.dropna(axis=0, subset=['CPI '], inplace=True)\n",
    "    data.rename(str.strip, axis='columns', inplace=True)\n",
    "    \n",
    "    data = data.replace({'-':0, '--':0, '---':0, '<':0, '>':0, 'Null':0, '12:00':2, 'O':0})\n",
    "    # Sex feature\n",
    "    data['Sex'] = data['Sex'].replace({'Male':0, 'Female':1})\n",
    "    \n",
    "    # Branch feature\n",
    "    data['Branch'] = data['Branch'].replace({'Design':0,\n",
    "                                         'CSE':1,\n",
    "                                         'MC':2,\n",
    "                                         'ECE/EEE':3,\n",
    "                                         'ME':4,\n",
    "                                         'CL':5,\n",
    "                                         'EP':6,\n",
    "                                         'CE':7,\n",
    "                                         'CST':8,\n",
    "                                         'BSBE':9})\n",
    "    \n",
    "    # Dropper feature\n",
    "    data['Dropper?'] = data['Dropper?'].replace({'Yes':1, 'No':0})\n",
    "    \n",
    "    # 10th Board & 12th Board Feature\n",
    "    data['10th Board'] = data['10th Board'].replace({'ICSE':2,\n",
    "                                                 'CBSE':1,\n",
    "                                                 'State':0})\n",
    "    data['12th Board'] = data['12th Board'].replace({'ICSE':2,\n",
    "                                                 'CBSE':1,\n",
    "                                                 'State':0})\n",
    "    \n",
    "    #Coaching Feature\n",
    "    data['Coaching'] = data['Coaching'].replace({'Yes':1, 'No':0})\n",
    "    \n",
    "    \n",
    "    # Coaching City, Coaching Name, Home State, Home City\n",
    "    #data = data.drop(['Coaching City', 'Coaching Name', 'Home State', 'Home City'], axis=1)\n",
    "    for col in ['Coaching City', 'Coaching Name', 'Home State', 'Home City', 'Mom\\'s Job', 'Dad\\'s Job']:\n",
    "        #for col in ['Coaching City', 'Coaching Name', 'Home City']:\n",
    "        data = string_col_preprocess(data, col, 8)\n",
    "        data = data.drop(col, axis=1)\n",
    "        \n",
    "        # Now replacing these values by descending order of mean (Label encoding by mean)\n",
    "        replace_dict = {}\n",
    "        for rank, key in enumerate(data.groupby(col+'Sound')['CPI'].mean().sort_values(ascending=False).keys()):\n",
    "            replace_dict[key] = rank+1\n",
    "        \n",
    "        data[col+'Sound'] = data[col+'Sound'].replace(replace_dict)\n",
    "    \n",
    "    # Mom Dad Education\n",
    "    data['Mom\\'s Education'] = data['Mom\\'s Education'].fillna('Post Graduate')\n",
    "    data['Mom\\'s Education'] = data['Mom\\'s Education'].replace({'<10th Pass':0,\n",
    "                                                                 '< 10th Pass':0,\n",
    "                                                                 '10th Pass':1,\n",
    "                                                                 '12th Pass':2,\n",
    "                                                                 'Graduate':3,\n",
    "                                                                 'Post Graduate':4})\n",
    "    data['Dad\\'s Education'] = data['Dad\\'s Education'].fillna('Post Graduate')\n",
    "    data['Dad\\'s Education'] = data['Dad\\'s Education'].replace({'<10th Pass':0,\n",
    "                                                                 '< 10th Pass':0,\n",
    "                                                                 '10th Pass':1,\n",
    "                                                                 '12th Pass':2,\n",
    "                                                                 'Graduate':3,\n",
    "                                                                 'Post Graduate':4})\n",
    "    \n",
    "    # Mom dad Job and Hostel\n",
    "    #for col in ['Mom\\'s Job', 'Dad\\'s Job', 'Hostel?']:\n",
    "    for col in ['Hostel?']:\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "    \n",
    "    # Study Time Feature\n",
    "    data['Study Time?'] = data['Study Time?'].fillna('Irregular')\n",
    "    data['Study Time?'] = data['Study Time?'].replace({'Irregular':0,\n",
    "                                                        'Everyday upto 0-2 hours':1,\n",
    "                                                        'Everyday upto 2-4 hours':2})\n",
    "    \n",
    "    # Technical Club Feature\n",
    "    #technical_dummy = data['Which Technical Clubs are you part of ?'].str.get_dummies(sep=', ')\n",
    "    #data = pd.concat([data.drop('Which Technical Clubs are you part of ?', axis=1), technical_dummy], axis=1)\n",
    "    \n",
    "    # Cultural Club Feature\n",
    "    #cult_dummy = data['Which Cultural Clubs are you part of?'].str.get_dummies(sep=', ')\n",
    "    #data = pd.concat([data.drop('Which Cultural Clubs are you part of?', axis=1), cult_dummy], axis=1)\n",
    "    \n",
    "    # Fest Feature\n",
    "    fest_dummy = data['Member of Fests\\' organizing team?'].str.get_dummies(sep=', ')\n",
    "    data = pd.concat([data.drop('Member of Fests\\' organizing team?', axis=1), fest_dummy], axis=1)\n",
    "    \n",
    "    # Education Loan Feature\n",
    "    data['Have you taken an educational loan?'] = data['Have you taken an educational loan?'].replace({'No':0, 'Yes':1})\n",
    "    \n",
    "    # Time Spent Outside Feature\n",
    "    data['Time spent outside your room[except classes]? (daily average, in hours)'] = data['Time spent outside your room[except classes]? (daily average, in hours)'].fillna(4)\n",
    "    \n",
    "    \n",
    "    #Attendance feature\n",
    "    data['Attendance?'] = data['Attendance?'].replace({'Below 50?':50,\n",
    "                                                       'Below 75?':62.5,\n",
    "                                                       'Below 90?':87.5,\n",
    "                                                       'Above 90?':95})\n",
    "    \n",
    "    # Relationship Feature\n",
    "    data['Relationship status?'] = data['Relationship status?'].replace({'Committed':0,\n",
    "                                                       'Complicated':0,\n",
    "                                                       'Single':1})\n",
    "    \n",
    "    # Library Feature\n",
    "    data['Library?'] = data['Library?'].replace({'Rarely':0,\n",
    "                                                 'During Exams':1,\n",
    "                                                 'Often':2})\n",
    "    \n",
    "    # Sleeping time\n",
    "    \"\"\"data['When do you sleep?'] = data['When do you sleep?'].replace({'Before 10 pm':0,\n",
    "                                                                     'After 10 pm':1,\n",
    "                                                                     'Around 12':2,\n",
    "                                                                     'After 12 am':3,\n",
    "                                                                     'Around 1':4,\n",
    "                                                                     'After 2 am':5,\n",
    "                                                                     '3':6,\n",
    "                                                                     3:6,\n",
    "                                                                     'Never':8,\n",
    "                                                                     '6:30 am':8})\"\"\"\n",
    "    data = data.drop(\"When do you sleep?\", axis=1)\n",
    "    \n",
    "    # Sleeping Duration\n",
    "    data['Sleep Duration(Hrs)?'] = data['Sleep Duration(Hrs)?'].replace({'<=4':-2,\n",
    "                                                                     '5':-1,\n",
    "                                                                     5:-1,\n",
    "                                                                     '6':0,\n",
    "                                                                     6:0,\n",
    "                                                                     '7':1,\n",
    "                                                                     7:1,\n",
    "                                                                     '>=8':2})\n",
    "    \n",
    "    # Sleep in Day\n",
    "    data['Do you sleep during the day?'] = data['Do you sleep during the day?'].replace({'Yes':1, 'No':0})\n",
    "    \n",
    "    # Addiction Feature\n",
    "    #addiction_dummy = data['Addiction?'].str.get_dummies(sep=', ')\n",
    "    #data = pd.concat([data.drop('Addiction?', axis=1), addiction_dummy], axis=1)\n",
    "    \n",
    "    # Group Study or Individual\n",
    "    data['Group Study/Individual'] = data['Group Study/Individual'].replace({'Group Study':1, 'Individual':0})\n",
    "    \n",
    "    # Study Material Preferred\n",
    "    data['Study Material Preferred'] = data['Study Material Preferred'].replace({'Online content':0, 'Books':1})\n",
    "    \n",
    "    # Core/NonCore\n",
    "    data['Core/Non-Core'] = data['Core/Non-Core'].replace({'Core':0, 'Non-Core':1})\n",
    "    \n",
    "    \n",
    "    # Missing Values\n",
    "    #data = pd.DataFrame(imp.fit_transform(data), columns=data.columns)\n",
    "    return data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = new_data['CPI']\n",
    "X = new_data.drop(['CPI'], axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "kbest = SelectKBest(score_func=f_regression, k=13)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "kbest = SelectKBest(score_func=f_regression, k=13)\n",
    "kbest.fit(X, y)\n",
    "\n",
    "X_new = kbest.transform(X)\n",
    "rdg = Ridge(alpha=35)\n",
    "#rf = RandomForestRegressor(min_samples_split=11, min_samples_leaf=12, n_estimators=500, max_depth=6)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rdg, X_new, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "preprocess_transformer = FunctionTransformer(preprocess_data)\n",
    "\n",
    "pipe = Pipeline([(\"preprocess\", preprocess_transformer), (\"kbest\", kbest), (\"model\", rdg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data__. = pd.read_csv(\"../input/data-...csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
